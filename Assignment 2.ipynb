{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Sieu Eric Diep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X:  (4600, 57)\n",
      "Type of X: \n",
      "word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest      int64\n",
      "capital_run_length_total        int64\n",
      "dtype: object\n",
      "\n",
      "Size of y:  (4600,)\n",
      "Type of y:  int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "\n",
    "from yellowbrick.datasets.loaders import load_spam\n",
    "(X,y) = load_spam()\n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "\n",
    "print(\"Size of X: \", X.shape)\n",
    "print(\"Type of X: \")\n",
    "print(X.dtypes)\n",
    "type(X)\n",
    "print(\"\");\n",
    "\n",
    "print(\"Size of y: \", y.shape)\n",
    "print(\"Type of y: \", y.dtype)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of missing values in: \n",
      " X:  word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;                   0\n",
      "char_freq_(                   0\n",
      "char_freq_[                   0\n",
      "char_freq_!                   0\n",
      "char_freq_$                   0\n",
      "char_freq_#                   0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "dtype: int64\n",
      " y:  0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(\"# of missing values in: \")\n",
    "print(\" X: \", X.isnull().sum())\n",
    "print(\" y: \", y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 57)\n",
      "(4370, 57)\n",
      "(230,)\n",
      "(4370,)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_small, X_small_test, y_small, y_small_test = train_test_split(X,y,train_size = 0.05, test_size = 0.95, random_state = 0)\n",
    "print(X_small.shape)\n",
    "print(X_small_test.shape)\n",
    "print(y_small.shape)\n",
    "print(y_small_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Data size Training Accuracy Validation Accuracy\n",
      "0  (4600, 57)          0.928696            0.938261\n",
      "1   (4600, 2)          0.608406            0.613043\n",
      "2   (230, 57)          0.936047            0.931034\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression(max_iter = 2000)\n",
    "\n",
    "#extracting the first two columns of X\n",
    "X_2col = X.iloc[:,0:2]\n",
    "#print(X_2col.head(5))\n",
    "\n",
    "#putting all the X and y into a list \n",
    "X_list = [X,X_2col,X_small]\n",
    "y_list = [y,y,y_small]\n",
    "\n",
    "#create an empty dataframe with 3 columns: Data size, training accuracy, validation accuracy\n",
    "results = pd.DataFrame(columns=[\"Data size\", \"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "i = 0\n",
    "\n",
    "for xdata, ydata in zip(X_list, y_list):\n",
    "    results.loc[i,\"Data size\"]= xdata.shape\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xdata, ydata, random_state=0)\n",
    "    lr = model.fit(X_train,y_train)\n",
    "    results.loc[i,\"Training Accuracy\"] = lr.score(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results.loc[i,\"Validation Accuracy\"]= accuracy_score(y_test, y_pred)\n",
    "    i += 1\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. In this dataset, the sample numbers (number of rows in the dataset) doesn't have a big impact on the accuracy score. The accuracy scores gained from 4600 rows of data is very similar (within 0.01 difference) to the scores gained from 5% of the origial dataset (230 rows). The models obtain from both of these dataset perform quite well, with the scores above 0.9, very close to 1. \n",
    "\n",
    "However, the number of features has a big impact on the accuracy scores. The model performs far worse with few features. The dataset with two features only acheives a score of 0.6 while a 57 features dataset acheives a score above 0.9. The model is underfit with less features provided, which oversimplifies the model.\n",
    "\n",
    "2. A true positive means is_spam = 1, in other words, it is spam. So false positive represents not_spam and false negative represents spam. The false negative means an important email would be classified as spam, and could be lost in the spam folder. Lost of information can create real damages. A false positive means a spam email would be classified as not_spam. This may cause some inconvinient, but not significant damage (assumming the email reader would excercises proper caution and measurement regarding cybersecurity). So a false negative is worse in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. First, I reviewed all the lecture notes to reinforce my understanding of the materials, then I reviewed the codes in the examples provided in the lectures. I find most of the codes in the jupiter notebook on D2L. I also checked the scikit website to read about how to load the dataset and how to use the train_test_split function\n",
    "https://www.scikit-yb.org/en/latest/api/datasets/index.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "2. I complete the steps according to the order of the instruction. I also checked and mirrored the order in the ML_ex_solution Jupyter notebook. I recognize that the order that I follow is actually the five steps in the Machine Learning Workflow stated in the lecture. \n",
    "\n",
    "3. I didn't use genertive AI to complete the assignment.\n",
    "\n",
    "4. I found that the lecture notes are quite comprehensive and straight forward. The concept is easy to understand, however the coding part is a little overwhelming although there's not a lot of them. The learning curve is a little steep that I went through the jupiter notebook many times to locate the correct codes that I need. I also looked up the codes in the user guide to understand each parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X:  (1030, 8)\n",
      "Type of X: \n",
      "cement    float64\n",
      "slag      float64\n",
      "ash       float64\n",
      "water     float64\n",
      "splast    float64\n",
      "coarse    float64\n",
      "fine      float64\n",
      "age         int64\n",
      "dtype: object\n",
      "\n",
      "Size of y:  (1030,)\n",
      "Type of y:  float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "import yellowbrick\n",
    "X,y = yellowbrick.datasets.loaders.load_concrete(data_home=None, return_dataset=False)\n",
    "# TO DO: Print size and type of X and y\n",
    "print(\"Size of X: \", X.shape)\n",
    "print(\"Type of X: \")\n",
    "print(X.dtypes)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Size of y: \", y.shape)\n",
    "print(\"Type of y: \", y.dtype)\n",
    "\n",
    "print(type(X))\n",
    "print(type(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # missing values in\n",
      "X:  cement    0\n",
      "slag      0\n",
      "ash       0\n",
      "water     0\n",
      "splast    0\n",
      "coarse    0\n",
      "fine      0\n",
      "age       0\n",
      "dtype: int64\n",
      "y:  0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(\"Total # missing values in\")\n",
    "print(\"X: \", X.isnull().sum())\n",
    "print(\"y: \", y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5041945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression coefficient:  [ 0.12185954  0.11060501  0.0953879  -0.1419938   0.31529263  0.02485841\n",
      "  0.02486899  0.11270849]\n",
      "intercept:  -36.541098199910955\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 0)\n",
    "lr = model.fit(X_train, y_train)\n",
    "\n",
    "print(\"linear regression coefficient: \", lr.coef_)\n",
    "print(\"intercept: \", lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "970c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "training_score = lr.score(X_train, y_train)\n",
    "val_score = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Training Accuracy Validation Accuracy\n",
      "MSE             111.358439           95.904136\n",
      "R2 Score          0.610823            0.623414\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Training Accuracy\", \"Validation Accuracy\"], index=[\"MSE\", \"R2 Score\"])\n",
    "results.iloc[0,0] = MSE(y_train,model.predict(X_train))\n",
    "results.iloc[0,1] = MSE(y_test, model.predict(X_test))\n",
    "results.iloc[1,:] = (training_score, val_score)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "#\n",
    "For this dataset, linear model doesn't produce a good result because the R2 score is only 0.6, which is far away (40% off) from 1. Although the variance here is quite low, but we want to achieve an R2 score as close to 1 as possible. There are non-linear feature in the dataset, that a linear model does not do well in predicting the result in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "\n",
    "After completing part 1 of the assigment, I found this part is a lot easier. I can found the code in the lectures and the examples provided in D2L. I didn't need to use the internet nor AI to source the code. \n",
    "\n",
    "I follow the steps exactly as per the assignment instructions. \n",
    "\n",
    "I don't find any challenges in this part because I have done enough study and practice in part 1 of the assignment. Practicing to get familiar with the code help a lot, and while doing the problems, the concept becomes clearer to me.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "In the lectures, it was mentioned that more data does not neccessary result in better model. It is confirmed in the part 1 that 5% of the dataset (about 230 rows) obtain more or less the same accuracy as a full dataset (over 4000 rows). This means that a well-diversed small sample can represent the model quite well. So starting with a small sample and increasing the datasize as we go would be a good practice. \n",
    "\n",
    "However, the accuracy score seems to be better, the more features we have in the dataset. A dataset with only 2 features performs significant worse than a dataset with 57 features. Noting that different features may have different weight on the performance, some may be a lot more important than the other. But missing too many features (57 vs 2) seems too have a very bad impact on the overall score. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "#My thought:\n",
    "It was quite confusing at first trying to understand the concept of underfitting/overfitting fully. But after carefully reading the materials, it's not bad and becomes interesting. I like the fact that the assignment gives me enough practice to reinforce the understanding of the materials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "alpha training_score validation_score\n",
      "0.001 \t 0.610823 \t 0.623414\n",
      "0.01 \t 0.610823 \t 0.623414\n",
      "0.1 \t 0.610823 \t 0.623415\n",
      "1 \t 0.610823 \t 0.623415\n",
      "10 \t 0.610823 \t 0.623418\n",
      "100 \t 0.610823 \t 0.623453\n",
      "\n",
      "Lasso\n",
      "alpha training_score validation_score\n",
      "0.001 \t 0.610823 \t 0.610823\n",
      "0.01 \t 0.610823 \t 0.610823\n",
      "0.1 \t 0.610821 \t 0.610821\n",
      "1 \t 0.610609 \t 0.610609\n",
      "10 \t 0.604314 \t 0.604314\n",
      "100 \t 0.467576 \t 0.467576\n"
     ]
    }
   ],
   "source": [
    "#Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "training_score = []\n",
    "validation_score = []\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "i = 0\n",
    "\n",
    "print(\"Ridge\\nalpha training_score validation_score\")\n",
    "\n",
    "for a in alpha :\n",
    "    ridge = Ridge(a).fit(X_train, y_train)\n",
    "    training_score.append(ridge.score(X_train, y_train))\n",
    "    validation_score.append(ridge.score(X_test, y_test))\n",
    "    print(\"{} \\t {:0.6f} \\t {:0.6f}\".format(a, training_score[i], validation_score[i]))\n",
    "    i +=1\n",
    "\n",
    "#Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "training_score_Lasso = []\n",
    "val_score_Lasso = []\n",
    "\n",
    "i = 0\n",
    "print(\"\\nLasso\\nalpha training_score validation_score\")\n",
    "for a in alpha:\n",
    "    lasso= Lasso(a, max_iter=100000).fit(X_train, y_train)\n",
    "    training_score_Lasso.append(lasso.score(X_train, y_train))\n",
    "    val_score_Lasso.append(lasso.score(X_train, y_train))\n",
    "    print(\"{} \\t {:0.6f} \\t {:0.6f}\".format(a, training_score_Lasso[i], val_score_Lasso[i]))\n",
    "    i +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "\n",
    "*ANSWER HERE*\n",
    "The accuracy scores didn't improve much with both the Lasso and Ridge method. They remain more or less the same \n",
    "around 0.6 even with different value of alpha. In Ridge, the training score doesn't change regardless of alpha, while the \n",
    "validation score improves very insignificantly when increase alpha. In Lasso, the scores remain more or less the same\n",
    "when alpha is between 0.001, 0.01 and 0.1. As alpha is increasing over 1, the scores decreases quite significantly (over 20%)\n",
    "from 0.61 (alpha = 1) to 0.47 (alpha = 100).\n",
    "\n",
    "The Ridge model seems to be a better model with a higher R score. But this score is still not good enough as it is still \n",
    "about 40% off from the max value of 1. Again, this means that the dataset is not linear in nature that a linear model simply \n",
    "is not suitable for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3c65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
